{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "class.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zryczv_KVye"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from concurrent.futures import ThreadPoolExecutor as pool\n",
        "from BotDetection import Wishart\n",
        "\n",
        "\n",
        "class TSProcessor:\n",
        "    def __init__(self, points_in_template: int, max_template_spread: int):\n",
        "\n",
        "        # максимальное расстояние между соседними зубчиками шаблона\n",
        "        self._max_template_spread = max_template_spread\n",
        "        self._points_in_template = points_in_template\n",
        "        self.x_dim: int = max_template_spread ** (points_in_template - 1)  # сколько у нас всего шаблонов\n",
        "        self.z_dim: int = points_in_template                               # сколько зубчиков в каждом шаблоне\n",
        "\n",
        "        # сами шаблоны\n",
        "        templates = (np.repeat(0, self.x_dim).reshape(-1, 1), )\n",
        "\n",
        "        for i in range(1, points_in_template):\n",
        "            col = (np.repeat(\n",
        "                np.arange(1, max_template_spread + 1, dtype=int), max_template_spread ** (points_in_template - (i + 1))\n",
        "            ) + templates[i - 1][::max_template_spread ** (points_in_template - i)]).reshape(-1, 1)\n",
        "\n",
        "            templates += (col, )  # don't touch\n",
        "\n",
        "        self._templates: np.ndarray = np.hstack(templates)\n",
        "\n",
        "        # формы шаблонов, т.е. [1, 1, 1], [1, 1, 2] и т.д.\n",
        "        self._template_shapes: np.ndarray = self._templates[:, 1:] - self._templates[:, :-1]\n",
        "\n",
        "    def fit(self, time_series: np.ndarray) -> None:\n",
        "        '''Обучить класс на конкретном ряду.'''\n",
        "\n",
        "        self._time_series   = time_series\n",
        "        self.y_dim          = self._time_series.size - self._templates[0][-1]\n",
        "        self._original_size = self._time_series.size\n",
        "\n",
        "        # создать обучающее множество\n",
        "        # Его можно представить как куб, где по оси X идут шаблоны, по оси Y - вектора,\n",
        "        # а по оси Z - индивидуальные точки векторов.\n",
        "        # Чтобы получить точку A вектора B шаблона C - делаем self._training_vectors[C, B, A].\n",
        "        # Вектора идут в хронологическом порядке \"протаскивания\" конкретного шаблона по ряду,\n",
        "        # шаблоны - по порядку от [1, 1, ... , 1], [1, 1, ..., 2] до [n, n, ..., n].\n",
        "        self._training_vectors: np.ndarray = \\\n",
        "            np.full(shape=(self.x_dim, self.y_dim, self.z_dim), fill_value=np.inf, dtype=float)\n",
        "\n",
        "        # тащим шаблон по ряду\n",
        "        for i in range(self.x_dim):\n",
        "            template_data = (\n",
        "                self._time_series[self._templates[i]\n",
        "                                  + np.arange(self._time_series.size - self._templates[i][-1])[:, None]]\n",
        "            )\n",
        "\n",
        "            self._training_vectors[i, :template_data.shape[0]] = (\n",
        "                self._time_series[self._templates[i]\n",
        "                                  + np.arange(self._time_series.size - self._templates[i][-1])[:, None]]\n",
        "            )\n",
        "\n",
        "    def pull(self, steps: int, eps: float, n_trajectories: int, noise_amp: float, prev_preds: np.array=None) -> np.ndarray:\n",
        "        '''\n",
        "        Основной метод пулла, который использовался в статье.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        steps : int\n",
        "            На сколько шагов прогнозируем.\n",
        "        eps : float\n",
        "            Минимальное Евклидово расстояние от соответствующего шаблона, в пределах которого должны находиться\n",
        "            вектора наблюдений, чтобы считаться \"достаточно похожими\".\n",
        "        n_trajectories : int\n",
        "            Сколько траекторий использовать. Чем больше, тем дольше время работы и потенциально точнее результат.\n",
        "        noise_amp : float\n",
        "            Максимальная амплитуда шума, используемая при расчете траекторий.\n",
        "        prev_preds: np.array - вектор предыдущих предсказаний (для запуска в цикле для self-healing)\n",
        "\n",
        "        Возвращает матрицу размером steps x n_trajectories, где по горизонтали идут шаги, а по вертикали - прогнозы\n",
        "        каждой из траекторий на этом шаге.\n",
        "        '''\n",
        "        # прибавляем к тренировочному датасету steps пустых векторов, которые будем заполнять значениями на ходу\n",
        "        # только при первом проходе, для self-healing это не повторяется\n",
        "        if prev_preds is None or self._training_vectors.shape[1] != self.y_dim + steps:\n",
        "            self._training_vectors = np.hstack([self._training_vectors,\n",
        "                                                np.full([self.x_dim, steps, self.z_dim], fill_value=np.inf)])\n",
        "\n",
        "        # удлиняем изначальый ряд на значение steps + delta\n",
        "        # delta - \"запас места\" справа для использования всех возмжных шаблонов\n",
        "        # к концу тестовой выборки \n",
        "        # (проблемы когда пронозируемая точка - непоследняя)\n",
        "        delta = self._max_template_spread * self._points_in_template\n",
        "        self._time_series = np.resize(\n",
        "            self._time_series,\n",
        "            self._original_size + steps + delta\n",
        "        )\n",
        "        if prev_preds is None:\n",
        "            prev_preds = np.array([np.nan])\n",
        "\n",
        "        # сеты прогнозных значений для каждой точки, в которой будем делать прогноз\n",
        "        forecast_sets = np.full((steps, n_trajectories), np.nan)\n",
        "        for i in range(n_trajectories):\n",
        "            self._time_series[self._original_size: self._original_size + steps] = prev_preds\n",
        "            self._time_series[self._original_size + steps:] = np.nan\n",
        "            for j in range(steps):\n",
        "                points = np.array([])\n",
        "                if len(prev_preds) == 1:\n",
        "                    rng = [self._points_in_template - 1]\n",
        "                else:\n",
        "                    rng = range(self._points_in_template - 1, 0, -1)\n",
        "                # цикл по всем возможным позициям пронозируемой точки в векторе\n",
        "                for pos_in_vec in rng:\n",
        "                    if pos_in_vec < self._points_in_template - 1:\n",
        "                        # переставка шаблона так, чтобы прогнозируемая точка оказалась последней\n",
        "                        # был шаблон 1, 2, 3 [n, n + 1, n + 3, n + 6]\n",
        "                        # хотим прогнозировать предполследнюю точку\n",
        "                        # получаем 1, 5, -3 [n, n + 1, n + 6, n + 3]\n",
        "                        template_shapes = np.hstack([\n",
        "                            self._template_shapes[:, : pos_in_vec - 1],\n",
        "                            (\n",
        "                                self._template_shapes[:, pos_in_vec - 1].reshape(-1, 1)\n",
        "                                + self._template_shapes[:, pos_in_vec].reshape(-1, 1)\n",
        "                            ),\n",
        "                            self._template_shapes[:, pos_in_vec + 1:],\n",
        "                            -np.sum(self._template_shapes[:, pos_in_vec:], axis=1).reshape(-1, 1)\n",
        "                        ])\n",
        "                    else:\n",
        "                        template_shapes = self._template_shapes\n",
        "\n",
        "                    # print(pos_in_vec, template_shapes[10], self._template_shapes[10])\n",
        "                    # тестовые вектора, которые будем сравнивать с тренировочными\n",
        "                    last_vectors = (self._time_series[:self._original_size + j + delta]\n",
        "                                    [np.cumsum(-template_shapes[:, ::-1], axis=1)[:, ::-1] - delta])\n",
        "                    if np.mean(np.isnan(last_vectors).any(axis=1)) == 1:\n",
        "                        continue\n",
        "\n",
        "                    # last_vectors = last_vectors[~np.isnan(last_vectors).any(axis=1), :]\n",
        "                    last_vectors = np.nan_to_num(last_vectors, True, np.inf, np.inf, np.inf)\n",
        "                    if len(last_vectors) == 0:\n",
        "                        continue\n",
        "                    distance_matrix = self._calc_distance_matrix(\n",
        "                        last_vectors,\n",
        "                        np.repeat(True, self.x_dim),\n",
        "                        steps,\n",
        "                        pos_in_vec,\n",
        "                        self._points_in_template\n",
        "                    )\n",
        "\n",
        "                    # последние точки тренировочных векторов, оказавшихся в пределах eps\n",
        "                    if points.size == 0:\n",
        "                        points = self._training_vectors[distance_matrix < eps][:, pos_in_vec]\n",
        "                    else:\n",
        "                        points = np.concatenate(\n",
        "                            [points, self._training_vectors[distance_matrix < eps][:, pos_in_vec]],\n",
        "                            axis=0\n",
        "                        )\n",
        "                # теперь нужно выбрать финальное прогнозное значение из возможных\n",
        "                # я выбираю самое часто встречающееся значение, но тут уже можно на свое усмотрение\n",
        "\n",
        "                forecast_point                             = self._freeze_point(points, 'mf') \\\n",
        "                    + random.uniform(-noise_amp, noise_amp)\n",
        "                self._time_series[self._original_size + j] = forecast_point\n",
        "\n",
        "                # у нас появилась новая точка в ряду, последние вектора обновились, добавим их в обучающие\n",
        "                new_training_vectors = (\n",
        "                    self._time_series[:self._original_size + 1 + j]\n",
        "                    [np.hstack((np.cumsum(-self._template_shapes[:, ::-1], axis=1)[:, ::-1]\n",
        "                    - 1, np.repeat(-1, self.x_dim).reshape(-1, 1)))]\n",
        "                )\n",
        "                self._training_vectors[:, self.y_dim + j, :] = new_training_vectors\n",
        "\n",
        "            # честно говоря, я не помню, зачем нужен код дальше\n",
        "\n",
        "            # delete added vectors after each run\n",
        "            self._training_vectors[:, self.y_dim:] = np.inf\n",
        "\n",
        "            # delete added points after each run\n",
        "            # self._time_series[-steps - delta:] = np.nan\n",
        "        return forecast_sets\n",
        "\n",
        "    def cluster_sets(self, forecast_sets: np.ndarray, dbs_eps: float, dbs_min_samples: int):\n",
        "        '''\n",
        "        Скластеризировать полученные в результате пулла множества прогнозных значений.\n",
        "        Возвращает центр самого большого кластера на каждом шаге.\n",
        "        '''\n",
        "\n",
        "        predictions = np.full(shape=[len(forecast_sets), ], fill_value=np.nan)\n",
        "        dbs         = DBSCAN(eps=dbs_eps, min_samples=dbs_min_samples)\n",
        "\n",
        "        for i in range(len(forecast_sets)):\n",
        "            curr_set = np.array(forecast_sets[i])\n",
        "            if len(curr_set) == 0:\n",
        "              predictions[i] = np.nan\n",
        "              continue\n",
        "            dbs.fit(curr_set.reshape(-1, 1))\n",
        "\n",
        "            cluster_labels, cluster_sizes = np.unique(dbs.labels_[dbs.labels_ > -1], return_counts=True)\n",
        "\n",
        "            if cluster_labels.size > 0:\n",
        "                biggest_cluster_center = curr_set[dbs.labels_ == cluster_labels[cluster_sizes.argmax()]].mean()\n",
        "                predictions[i] = biggest_cluster_center\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def _calc_distance_matrix(self, test_vectors: np.ndarray, mask: np.ndarray, steps: int, pos_in_vec = 3, vec_len = 4) -> np.ndarray:\n",
        "        '''\n",
        "        По необъяснимым причинам считать матрицу расстояний между тестовыми векторами и тренировочными быстрее вот так.\n",
        "        '''\n",
        "        # переставка шаблона так, чтобы прогнозируемая точка оказалась последней\n",
        "        # был шаблон 1, 2, 3 [n, n + 1, n + 3, n + 6]\n",
        "        # хотим прогнозировать предполследнюю точку\n",
        "        # получаем 1, 5, -3 [n, n + 1, n + 6, n + 3]\n",
        "        training_vectors = np.concatenate(\n",
        "            [\n",
        "                self._training_vectors[mask, :, :pos_in_vec],\n",
        "                self._training_vectors[mask, :, pos_in_vec + 1:],\n",
        "                self._training_vectors[mask, :, pos_in_vec:pos_in_vec+1]\n",
        "            ],\n",
        "            axis=2\n",
        "        )\n",
        "        distance_matrix = ((training_vectors[:, :, 0] - np.repeat(test_vectors[:, 0], self.y_dim + steps)\n",
        "                            .reshape(-1, self.y_dim + steps)) ** 2)\n",
        "        for i in range(1, vec_len - 1):\n",
        "             distance_matrix += ((training_vectors[:, :, i] - np.repeat(test_vectors[:, i], self.y_dim + steps)\n",
        "                                .reshape(-1, self.y_dim + steps)) ** 2)\n",
        "        distance_matrix = distance_matrix ** 0.5\n",
        "\n",
        "        return distance_matrix\n",
        "\n",
        "    def _freeze_point(self, points_pool: np.ndarray, how: str, dbs_eps: float = 0.0, dbs_min_samples: int = 0) -> float:\n",
        "        '''\n",
        "        Выбрать финальный прогноз в данной точке из множества прогнозных значений.\n",
        "\n",
        "        \"How\" варианты:\n",
        "            \"mean\" = \"mean\"\n",
        "            \"mf\"   = \"most frequent\"\n",
        "            \"cl\"   = \"cluster\", нужны dbs_eps и dbs_min_samples\n",
        "        '''\n",
        "\n",
        "        if points_pool.size == 0:\n",
        "            result = np.nan\n",
        "        else:\n",
        "            if how == 'mean':\n",
        "                result = float(points_pool.mean())\n",
        "\n",
        "            elif how == 'mf':\n",
        "                points, counts = np.unique(points_pool, return_counts=True)\n",
        "                result         = points[counts.argmax()]\n",
        "\n",
        "            elif how == 'cl':\n",
        "                ms = max(10, len(points_pool) // 10)\n",
        "                dbs = DBSCAN(eps=dbs_eps, min_samples=ms)\n",
        "                dbs.fit(points_pool.reshape(-1, 1))\n",
        "\n",
        "                cluster_labels, cluster_sizes = np.unique(dbs.labels_[dbs.labels_ > -1], return_counts=True)\n",
        "\n",
        "                if (cluster_labels.size > 0\n",
        "                        and np.count_nonzero(((cluster_sizes / cluster_sizes.max()).round(2) > 0.8)) == 1):\n",
        "                    biggest_cluster_center = points_pool[dbs.labels_ == cluster_labels[cluster_sizes.argmax()]].mean()\n",
        "                    result                 = biggest_cluster_center\n",
        "                else:\n",
        "                    result = np.nan\n",
        "            elif how == 'w':\n",
        "              if len(points_pool) <= 6:\n",
        "                points, counts = np.unique(points_pool, return_counts=True)\n",
        "                result  = points[counts.argmax()]\n",
        "                return result\n",
        "              wsht = Wishart.Wishart(5, 10000000000)\n",
        "              r = wsht.fit(points_pool.reshape(-1, 1))\n",
        "              #print(r)\n",
        "              points, counts = np.unique(r, return_counts=True)\n",
        "              number  = points[counts.argmax()]\n",
        "              result = points_pool[r == number].mean()\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _fish(self, steps: int, eps: float, current_step: int) -> list:\n",
        "        '''\n",
        "        \"Закидываем удочку\". Из текущей точки закидываем все шаблоны вперед, насколько позволяет их длина, и сохраняем\n",
        "        последние точки соответствующих обучающих векторов в массив points, которые затем аггрегируем в \"общий\" список\n",
        "        forecasted_points.\n",
        "        '''\n",
        "\n",
        "        forecasted_points = []\n",
        "\n",
        "        # длина удочки = максимальное расстояние между соседними зубчиками в шаблоне\n",
        "        for i in range(min(self._max_template_spread, steps - current_step)):\n",
        "            # вектора, последняя точка которых \"висит в воздухе\"\n",
        "            last_vectors = (\n",
        "                self._time_series[:self._original_size + current_step]\n",
        "                [np.cumsum(-self._template_shapes[:, ::-1], axis=1)[:, ::-1]\n",
        "                 + (self._template_shapes[:, -1] - 1).reshape(-1, 1)]\n",
        "            )\n",
        "            # отсеиваем \"недостаточно длинные\" шаблоны\n",
        "            length_mask = self._template_shapes[:, -1] > i\n",
        "\n",
        "            # убираем вектора, в которые попадают непрогнозируемые точки\n",
        "            non_nan_mask = ~np.isnan(last_vectors).any(axis=1)\n",
        "\n",
        "            total_mask = length_mask & non_nan_mask\n",
        "\n",
        "            last_vectors    = last_vectors[total_mask]\n",
        "            distance_matrix = self._calc_distance_matrix(last_vectors, total_mask, steps)\n",
        "\n",
        "            points = self._training_vectors[total_mask][distance_matrix < eps, -1]\n",
        "            forecasted_points.append(points)\n",
        "\n",
        "        return forecasted_points\n",
        "\n",
        "    def push(self, steps, eps, dbs_eps = 0.01, dbs_min_samples = 10):\n",
        "        self._training_vectors     = np.hstack([self._training_vectors,\n",
        "                                                np.full([self.x_dim, steps, self.z_dim], fill_value=np.inf)])\n",
        "        self._time_series          = np.resize(self._time_series, self._original_size + steps)\n",
        "        self._time_series[-steps:] = np.nan\n",
        "        point_pools                = [[] for _ in range(steps)]\n",
        "\n",
        "        for back_point in range(steps):  # двигаем задний порог\n",
        "            front_point = back_point\n",
        "\n",
        "            # двигаем передний порог\n",
        "            print(front_point)\n",
        "            while front_point < min(front_point + self._max_template_spread, steps):\n",
        "                if np.isnan(self._time_series[self._original_size - 1 + front_point]):\n",
        "                    front_point += 1\n",
        "                    continue\n",
        "                forecasted_points = self._fish(steps, eps, front_point)\n",
        "                for i in range(len(forecasted_points)):\n",
        "                    point_pools[front_point + i].extend(forecasted_points[i])\n",
        "                    #points, counts = np.unique(point_pools[front_point + i], return_counts=True)\n",
        "                    #if len(points) != 0:\n",
        "                    #  result = points[counts.argmax()]\n",
        "                    #else:\n",
        "                    #  result = np.nan\n",
        "                    #self._time_series[self._original_size + front_point + i] = result\n",
        "                    self._time_series[self._original_size + front_point + i] =\\\n",
        "                        self._freeze_point(np.array(point_pools[front_point + i]), 'w', dbs_eps, dbs_min_samples)\n",
        "                       #self._freeze_point(np.array(forecasted_points[i]), 'w', dbs_eps, dbs_min_samples)\n",
        "                front_point += 1\n",
        "\n",
        "\n",
        "            # добавляем только что полученные новые вектора к обучающим\n",
        "            #self._training_vectors[:, -steps] = self._time_series[:self._original_size + back_point + 1][\n",
        "            #    np.hstack([\n",
        "            #        np.cumsum(-self._template_shapes[:, ::-1], axis=1)[:, ::-1] - 1,\n",
        "            #        np.repeat(-1, self.x_dim).reshape(-1, 1)\n",
        "            #    ])\n",
        "            #]\n",
        "            #print(-self._template_shapes[:, ::-1])\n",
        "            #print(np.cumsum(-self._template_shapes[:, ::-1], axis=1)[:, ::-1])\n",
        "\n",
        "            back_point += 1\n",
        "\n",
        "        return self._time_series[-steps:], point_pools\n",
        "    def self_healing_push(self, steps, eps, dbs_eps = 0.01, dbs_min_samples = 10, noise_amp = 0.01, prev_preds: np.array=None):\n",
        "\n",
        "        if prev_preds is None or self._training_vectors.shape[1] != self.y_dim + steps:\n",
        "            self._training_vectors = np.hstack([self._training_vectors,\n",
        "                                                np.full([self.x_dim, steps, self.z_dim], fill_value=np.inf)])\n",
        "\n",
        "        # удлиняем изначальый ряд на значение steps + delta\n",
        "        # delta - \"запас места\" справа для использования всех возмжных шаблонов\n",
        "        # к концу тестовой выборки \n",
        "        # (проблемы были бы когда пронозируемая точка - непоследняя)\n",
        "        delta = self._max_template_spread * self._points_in_template\n",
        "        self._time_series = np.resize(\n",
        "            self._time_series,\n",
        "            self._original_size + steps + delta\n",
        "        )\n",
        "        if prev_preds is None:\n",
        "            prev_preds = np.array([np.nan])\n",
        "        self._time_series[self._original_size: self._original_size + steps] = prev_preds\n",
        "        self._time_series[self._original_size + steps:] = np.nan\n",
        "        point_pools = [[] for _ in range(steps)]\n",
        "\n",
        "        for back_point in range(steps):  # двигаем задний порог\n",
        "            front_point = back_point\n",
        "\n",
        "            # двигаем передний порог\n",
        "            print(front_point)\n",
        "            while front_point < min(front_point + self._max_template_spread, steps):\n",
        "                if np.isnan(self._time_series[self._original_size - 1 + front_point]):\n",
        "                    front_point += 1\n",
        "                    continue\n",
        "                forecasted_points = self._fish(steps, eps, front_point)\n",
        "                for i in range(len(forecasted_points)):\n",
        "                    point_pools[front_point + i].extend(forecasted_points[i])\n",
        "                    if not np.isnan(self._time_series[self._original_size + front_point + i]):\n",
        "                      \n",
        "                      #forecasted_points[i].append(self._time_series[self._original_size + front_point + i], axis = 0)\n",
        "                      all_points = np.append(np.array(forecasted_points[i]), np.array([self._time_series[self._original_size + front_point + i]]))\n",
        "                    else:\n",
        "                      all_points = np.array(forecasted_points[i])\n",
        "                    #print(point_pools[front_point + i])\n",
        "                    self._time_series[self._original_size + front_point + i] =\\\n",
        "                      self._freeze_point(np.array(point_pools[front_point + i]), 'cl', dbs_eps, dbs_min_samples)\n",
        "                      #self._freeze_point(all_points, 'mf', dbs_eps, dbs_min_samples)\n",
        "                      #self._freeze_point(np.array(point_pools[front_point + i]), 'w', dbs_eps, dbs_min_samples)\n",
        "                       #self._freeze_point(np.array(forecasted_points[i]), 'w', dbs_eps, dbs_min_samples)\n",
        "                front_point += 1\n",
        "            #добавляем self-healing\n",
        "            #front_point = min(front_point + self._max_template_spread, steps)\n",
        "            while front_point >= back_point:\n",
        "              points = np.array([])\n",
        "              if len(prev_preds) == 1:\n",
        "                  rng = [self._points_in_template - 1]\n",
        "              else:\n",
        "                  rng = range(self._points_in_template - 1, 0, -1)\n",
        "                # цикл по всем возможным позициям пронозируемой точки в векторе\n",
        "              for pos_in_vec in rng:\n",
        "                #print(front_point, pos_in_vec, \"front + pos in vec\")\n",
        "                if pos_in_vec < self._points_in_template - 1:\n",
        "                        # переставка шаблона так, чтобы прогнозируемая точка оказалась последней\n",
        "                        # был шаблон 1, 2, 3 [n, n + 1, n + 3, n + 6]\n",
        "                        # хотим прогнозировать предполследнюю точку\n",
        "                        # получаем 1, 5, -3 [n, n + 1, n + 6, n + 3]\n",
        "                  template_shapes = np.hstack([\n",
        "                    self._template_shapes[:, : pos_in_vec - 1],\n",
        "                    (\n",
        "                        self._template_shapes[:, pos_in_vec - 1].reshape(-1, 1)\n",
        "                        + self._template_shapes[:, pos_in_vec].reshape(-1, 1)\n",
        "                    ),\n",
        "                    self._template_shapes[:, pos_in_vec + 1:],\n",
        "                    -np.sum(self._template_shapes[:, pos_in_vec:], axis=1).reshape(-1, 1)\n",
        "                  ])\n",
        "                  #print(\"template_shapes\", template_shapes[0])\n",
        "                else:\n",
        "                    template_shapes = self._template_shapes\n",
        "                last_vectors = (self._time_series[:self._original_size + front_point + delta]\n",
        "                                    [np.cumsum(-template_shapes[:, ::-1], axis=1)[:, ::-1] - delta])\n",
        "                if np.mean(np.isnan(last_vectors).any(axis=1)) == 1:\n",
        "                    #print(\"isnan\")\n",
        "                    continue\n",
        "\n",
        "                last_vectors = np.nan_to_num(last_vectors, True, np.inf, np.inf, np.inf)\n",
        "                if len(last_vectors) == 0:\n",
        "                    continue\n",
        "                distance_matrix = self._calc_distance_matrix(\n",
        "                    last_vectors,\n",
        "                    np.repeat(True, self.x_dim),\n",
        "                    steps,\n",
        "                    pos_in_vec,\n",
        "                    self._points_in_template\n",
        "                )\n",
        "\n",
        "                # последние точки тренировочных векторов, оказавшихся в пределах eps\n",
        "                if points.size == 0:\n",
        "                    points = self._training_vectors[distance_matrix < eps][:, pos_in_vec]\n",
        "                else:\n",
        "                    points = np.concatenate(\n",
        "                        [points, self._training_vectors[distance_matrix < eps][:, pos_in_vec]],\n",
        "                        axis=0\n",
        "                    )\n",
        "              if not np.isnan(self._time_series[self._original_size + front_point]):\n",
        "                  points = np.append(np.array(points), np.array([self._time_series[self._original_size + front_point]]))\n",
        "              #print(points)\n",
        "              forecast_point = self._freeze_point(points, 'cl', dbs_eps = 0.01, dbs_min_samples = 10)\n",
        "              #print(forecast_point)\n",
        "              self._time_series[self._original_size + front_point] = forecast_point\n",
        "              front_point -= 1\n",
        "            print(self._time_series[self._original_size: self._original_size + steps])\n",
        "            rez = self._time_series[self._original_size: self._original_size + steps]\n",
        "            plt.plot(data[split: split + steps])\n",
        "            plt.scatter(range(rez.size), rez, c='orange')\n",
        "            plt.plot(range(rez.size), rez, c='orange')\n",
        "            plt.show()\n",
        "            \n",
        "            # добавляем только что полученные новые вектора к обучающим\n",
        "            #self._training_vectors[:, -steps] = self._time_series[:self._original_size + back_point + 1][\n",
        "            #  np.hstack([\n",
        "            #        np.cumsum(-self._template_shapes[:, ::-1], axis=1)[:, ::-1] - 1,\n",
        "            #        np.repeat(-1, self.x_dim).reshape(-1, 1)\n",
        "            #    ])\n",
        "            #]\n",
        "            #print(-self._template_shapes[:, ::-1])\n",
        "            #print(np.cumsum(-self._template_shapes[:, ::-1], axis=1)[:, ::-1])\n",
        "\n",
        "            back_point += 1\n",
        "\n",
        "        return self._time_series[self._original_size: self._original_size + steps], point_pools\n",
        "\n",
        "    def self_healing(self, steps, eps, dbs_eps = 0.01, dbs_min_samples = 10, noise_amp = 0.01, prev_preds: np.array=None):\n",
        "          if prev_preds is None or self._training_vectors.shape[1] != self.y_dim + steps:\n",
        "            self._training_vectors = np.hstack([self._training_vectors,\n",
        "                                                np.full([self.x_dim, steps, self.z_dim], fill_value=np.inf)])\n",
        "\n",
        "        # удлиняем изначальый ряд на значение steps + delta\n",
        "        # delta - \"запас места\" справа для использования всех возмжных шаблонов\n",
        "        # к концу тестовой выборки \n",
        "        # (проблемы были бы когда пронозируемая точка - непоследняя)\n",
        "          delta = self._max_template_spread * self._points_in_template\n",
        "          self._time_series = np.resize(\n",
        "            self._time_series,\n",
        "            self._original_size + steps + delta\n",
        "          )\n",
        "          if prev_preds is None:\n",
        "            prev_preds = np.array([np.nan])\n",
        "          self._time_series[self._original_size: self._original_size + steps] = prev_preds\n",
        "          self._time_series[self._original_size + steps:] = np.nan\n",
        "          point_pools = [[] for _ in range(steps)]\n",
        "          for front_point in range(steps):\n",
        "            points = np.array([])\n",
        "            if len(prev_preds) == 1:\n",
        "                rng = [self._points_in_template - 1]\n",
        "            else:\n",
        "                rng = range(self._points_in_template - 1, 0, -1)\n",
        "                # цикл по всем возможным позициям пронозируемой точки в векторе\n",
        "            for pos_in_vec in rng:\n",
        "              #print(front_point, pos_in_vec, \"front + pos in vec\")\n",
        "              if pos_in_vec < self._points_in_template - 1:\n",
        "                        # переставка шаблона так, чтобы прогнозируемая точка оказалась последней\n",
        "                        # был шаблон 1, 2, 3 [n, n + 1, n + 3, n + 6]\n",
        "                        # хотим прогнозировать предполследнюю точку\n",
        "                        # получаем 1, 5, -3 [n, n + 1, n + 6, n + 3]\n",
        "                template_shapes = np.hstack([\n",
        "                  self._template_shapes[:, : pos_in_vec - 1],\n",
        "                  (\n",
        "                      self._template_shapes[:, pos_in_vec - 1].reshape(-1, 1)\n",
        "                      + self._template_shapes[:, pos_in_vec].reshape(-1, 1)\n",
        "                  ),\n",
        "                  self._template_shapes[:, pos_in_vec + 1:],\n",
        "                  -np.sum(self._template_shapes[:, pos_in_vec:], axis=1).reshape(-1, 1)\n",
        "                ])\n",
        "                #print(\"template_shapes\", template_shapes[0])\n",
        "              else:\n",
        "                  template_shapes = self._template_shapes\n",
        "              last_vectors = (self._time_series[:self._original_size + front_point + delta]\n",
        "                                  [np.cumsum(-template_shapes[:, ::-1], axis=1)[:, ::-1] - delta])\n",
        "              if np.mean(np.isnan(last_vectors).any(axis=1)) == 1:\n",
        "                  #print(\"isnan\")\n",
        "                  continue\n",
        "\n",
        "              last_vectors = np.nan_to_num(last_vectors, True, np.inf, np.inf, np.inf)\n",
        "              if len(last_vectors) == 0:\n",
        "                  continue\n",
        "              distance_matrix = self._calc_distance_matrix(\n",
        "                  last_vectors,\n",
        "                  np.repeat(True, self.x_dim),\n",
        "                  steps,\n",
        "                  pos_in_vec,\n",
        "                  self._points_in_template\n",
        "              )\n",
        "\n",
        "                # последние точки тренировочных векторов, оказавшихся в пределах eps\n",
        "              if points.size == 0:\n",
        "                points = self._training_vectors[distance_matrix < eps][:, pos_in_vec]\n",
        "              else:\n",
        "                points = np.concatenate(\n",
        "                      [points, self._training_vectors[distance_matrix < eps][:, pos_in_vec]],\n",
        "                      axis=0\n",
        "                )\n",
        "            if not np.isnan(self._time_series[self._original_size + front_point]):\n",
        "                  points = np.append(np.array(points), np.array([self._time_series[self._original_size + front_point]]))\n",
        "              #print(points)\n",
        "            forecast_point = self._freeze_point(points, 'cl', dbs_eps = 0.01, dbs_min_samples = 10)\n",
        "            print(forecast_point)\n",
        "            self._time_series[self._original_size + front_point] = forecast_point\n",
        "          return self._time_series[self._original_size: self._original_size + steps]\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}